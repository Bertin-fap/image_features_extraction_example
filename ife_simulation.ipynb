{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm validation using a synthesis image\n",
    "The synthesis image is the sum of :\n",
    "- a background extracted from a confocal image;\n",
    "- sinusoides mimiking the saw marks;\n",
    "- of cylinders mimiking the features.\n",
    "\n",
    "$$\\begin{array}{l}\n",
    "im\\_synth({x_i},{y_j}) = background({x_i},{y_j}) + \\sum\\limits_h {{A_h}\\sin ({f_h}{y_j}) + \\sum\\limits_f {{\\mathop{\\rm circle}\\nolimits} ({x_i},{y_j},{x_{0,f}},{y_{0,f}},{r_f}} } ,{h_f})\\\\\n",
    "{\\mathop{\\rm circle}\\nolimits} ({x_i},{y_j},{x_{0,f}},{y_{0,f}},{r_f},{h_f}) = \\left\\{ {\\begin{array}{*{20}{c}}\n",
    "{ - {h_f}\\hspace{0.5cm}{\\rm{ if }}\\hspace{0.5cm}\\sqrt {{{\\left( {{x_{0,f}} - {x_i}} \\right)}^2} + {{\\left( {{y_{0,f}} - {y_j}} \\right)}^2}}  \\le {r_f}}\\\\\n",
    "{0\\hspace{0.5cm}{\\rm{ if }}\\hspace{0.5cm}\\sqrt {{{\\left( {{x_{0,f}} - {x_i}} \\right)}^2} + {{\\left( {{y_{0,f}} - {y_j}} \\right)}^2}}  > {r_f}}\n",
    "\\end{array}} \\right.\n",
    "\\end{array}$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Standard library imports\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "\n",
    "# Path of 'site-packages' where useful packages are stored on MAC-OS\n",
    "mac_packages = \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages\"    \n",
    "    \n",
    "# Root directory for all files \n",
    "root = Path(\"C:/Users/franc/OneDrive/Bureau/confocal/fichiers\")\n",
    "if not os.path.isdir(root) : \n",
    "    root = Path('/Users/amal/Gwyddion Images /Carton-Louise') \n",
    "store_file = root / Path('synthesis.xlsx')\n",
    "\n",
    "# Parameters of image reference \n",
    "cut_number = '119'\n",
    "wafer_number = '2'\n",
    "image_ref = 'c'\n",
    "\n",
    "# Specification of the directories of the experimental files and files names\n",
    "root_input = root / Path('cut ' + cut_number) / Path('wafer ' + wafer_number) / Path('save_plu')\n",
    "input_file_name = Path('wafer' + wafer_number +'-' + image_ref +'.plu') # input file \n",
    "\n",
    "# Specification of the directories of the output files and files names\n",
    "root_output = root / Path('cut ' + cut_number) / Path('wafer ' + wafer_number)\n",
    "file_xlsx_th = Path('im_synth.xlsx')      # file EXEL features features sythezed image\n",
    "file_xlsx_res = Path('im_synth_res.xlsx') # file EXEL features morphological analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell generates an image (N rows by M columns), with cylindrical features of radius r; depth h\n",
    "at x0, y0 postion in µm. A background extacted from an experimental image is added\n",
    "The features can be generated both by a determinitic way or by a random procedure.\n",
    "\n",
    "'''\n",
    "\n",
    "# 3rd party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Add package image_features_extract\n",
    "try: # standard storage path of 'site-packages' on WIN\n",
    "    import image_features_extract as ife\n",
    "except: # Add storage path of 'site-packages' on MAC-OS\n",
    "    import sys\n",
    "    sys.path.append(mac_packages)\n",
    "    import image_features_extract as ife\n",
    "    \n",
    "test = 0 #  deterministic features generation test =1\n",
    "         # random features generation test = 0\n",
    "\n",
    "#  description of features for deterministic generation (x0, y0, r, h) in µm\n",
    "features = [(50,50,5,1),(80,50,5,1),(100,50,5,1),(150,50,5,1),(200,50,5,1),\n",
    "               (200,350,20,1.5),(200,200,15,1.4),(500,500,20,1.2)]\n",
    "\n",
    "#  Number of features for random generation \n",
    "random_feature = {}\n",
    "random_feature['n_indent'] = 20 # number of indentation features\n",
    "random_feature['n_small'] = 5 # small features\n",
    "random_feature['n_cleavage'] = 20  # cleavage features generation\n",
    "\n",
    "\n",
    "cir = lambda X,Y : np.where((np.sqrt((X-x0)**2+(Y-y0)**2)-r) < 0, h,0.0)\n",
    "\n",
    "\n",
    "# background determination\n",
    "file = root_input / input_file_name\n",
    "N,M,conf_img,_ = ife.read_plu_topography(file) # fle .plu reading\n",
    "conf_img = ife.fill_gap(conf_img)              # substitute non measured values by interpolated ones \n",
    "\n",
    "im_flat = ife.image_flattening(conf_img, method_flat='poly',kx=5,ky=5) # image background removal\n",
    "im_synth = conf_img - im_flat                                          # image background extraction\n",
    "\n",
    "x = np.array(range(M))\n",
    "y = np.array(range(N))\n",
    "\n",
    "# saw marks generation\n",
    "sines = [(0.1,200),(0.05,50),(0.2,20)] \n",
    "for sine in sines:\n",
    "    A,f = sine\n",
    "    im_synth = im_synth+ A*np.sin(f*y/N).reshape((N,1))\n",
    "\n",
    "dict_feature = {}\n",
    "X,Y = np.meshgrid(x,y)\n",
    "\n",
    "# features generation\n",
    "if test==1: # deterministic features generation\n",
    "\n",
    "    for idx,feature in enumerate(features):\n",
    "        x0, y0, r, h = feature\n",
    "        c = cir(X,Y)\n",
    "        dict_feature[idx+1] = [x0,y0,r,h,len(np.where(c==h)[0])]\n",
    "        im_synth = im_synth - c\n",
    "        \n",
    "else:   # random features generation\n",
    "    n_features = random_feature['n_indent'] # number of indentation features\n",
    "    num_feature=1   # feature index\n",
    "    for idx in range(n_features):\n",
    "        x0 = np.random.randint(1,M) # x location of the feature limited to image width (M pixels)\n",
    "        if idx%5 ==0 : y0 = np.random.randint(1,N) # force 5 features alignement on a row\n",
    "                                                   # y location of the feature limited to image height (N pixels)\n",
    "        r = np.random.randint(1,5) # radius range limited to 1 - 5 µm\n",
    "        h = 0.5 # uniform indent depth may be randomized using np.random.randint(1,200)*0.01\n",
    "        c = cir(X,Y)\n",
    "        dict_feature[num_feature] = [x0,y0,r,h,len(np.where(c==h)[0])]\n",
    "        im_synth = im_synth - c\n",
    "        num_feature += 1\n",
    "\n",
    "    n_features = random_feature['n_small'] # small features\n",
    "    for idx in range(n_features):\n",
    "        x0 = np.random.randint(1,M)  # x location of the feature limited to image width (M pixels)\n",
    "        y0 = np.random.randint(1,N)  # y location of the feature limited to image height (N pixels)\n",
    "        r = np.random.randint(1,5)   # radius range limited to 1 - 5 µm\n",
    "        h = np.random.randint(1,200)*0.01 # depth range limited to 0.01 - 2 µm\n",
    "        c = cir(X,Y)\n",
    "        dict_feature[num_feature] = [x0,y0,r,h,len(np.where(c==h)[0])]\n",
    "        im_synth = im_synth - c\n",
    "        num_feature += 1\n",
    "\n",
    "    n_features = random_feature['n_cleavage']  # cleavage features generation\n",
    "    for _ in range(n_features):\n",
    "        x0 = np.random.randint(1,M) # x location of the feature limited to image width (M pixels)\n",
    "        y0 = np.random.randint(1,N) # y location of the feature limited to image height (N pixels)\n",
    "        r = np.random.randint(6,20)        # radius range limited to 6 - 20 µm\n",
    "        h = np.random.randint(50,200)*0.01 # depth range limited to 0.5 - 2 µm\n",
    "        c = cir(X,Y)\n",
    "        dict_feature[num_feature] = [x0,y0,r,h,len(np.where(c==h)[0])]\n",
    "        im_synth = im_synth - c\n",
    "        num_feature += 1\n",
    "df_th = pd.DataFrame.from_dict(dict_feature, orient='index',columns=[\"x\",\"y\",\"r\",\"height\",\"size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generated image processing:\n",
    "- saw marks removal and background correction using a top hat filter with a pattern length\n",
    "larger than the largest feature to extract\n",
    "- image binarization using a threshold on feature depth larger than the residual image background\n",
    "- features morphological analysis (using the scipy label function). Generate a\n",
    "        dataframe  index|'x'|'long_x'| 'y'|'long_y'| 'size'|'depth' where\n",
    "            - index: feature index\n",
    "            - x: gravity center x position of the feature\n",
    "            - long_x: maximum feature width\n",
    "            - y: gravity center y position of the feature\n",
    "            - long_y: maximum feature height\n",
    "            - size: pixels number of the feature \n",
    "            - depth : feature depth\n",
    "\n",
    "Plot of the results (images, histogram, box plot)\n",
    "\n",
    "Store the results in an excel file\n",
    "\n",
    "'''\n",
    "\n",
    "# 3rd party imports\n",
    "import numpy as np\n",
    "import matplotlib.colors as colx\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add package image_features_extract\n",
    "try: # standard storage path of 'site-packages' on WIN\n",
    "    import image_features_extract as ife\n",
    "except: # Add storage path of 'site-packages' on MAC-OS\n",
    "    import sys\n",
    "    sys.path.append(mac_packages)\n",
    "    import image_features_extract as ife\n",
    "    \n",
    "%matplotlib inline\n",
    "\n",
    "store_flag = True # if store_flag = True we store the resuts in an excel file\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "# parameters initialization\n",
    "Top_hat_length = 200 #  should be larger than the largest feature to extract\n",
    "threshold = -0.2     # should be larger than the residual image background\n",
    "\n",
    "# top hat processing\n",
    "im_corr = ife.top_hat_flattening(im_synth,Top_hat_length,top_hat_sens=-1)\n",
    "\n",
    "# binarization\n",
    "im_bin = np.where(im_corr < threshold, 1, 0) # binarization\n",
    "\n",
    "df = ife.analyse_morphologique(im_bin,im_corr) # morphological analysis df dataframe\n",
    "\n",
    "# generated image plot\n",
    "plt.subplot(3,2,1)\n",
    "plt.imshow(im_synth, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('Raw image')\n",
    "\n",
    "\n",
    "# top-hat filtered image plot\n",
    "plt.subplot(3,2,2)\n",
    "plt.imshow(im_corr, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title(f'Top hat length: {Top_hat_length}')\n",
    "\n",
    "# binarized image plot\n",
    "plt.subplot(3,2,3)\n",
    "plt.imshow(im_bin, cmap='gray')\n",
    "plt.colorbar() \n",
    "plt.title(f'Threshold: {threshold} µm')\n",
    "\n",
    "# reconstructed image plot\n",
    "plt.subplot(3,2,4)\n",
    "colorsMap = plt.get_cmap(\"plasma\") #(\"RdYlGn\")\n",
    "g = list(zip(np.array(df['x']),\n",
    "             np.array(df['y']),\n",
    "             np.array(df['height']),\n",
    "             np.array(df['size'])))\n",
    "x,y,c,s=zip(*sorted(g, key=lambda tup: tup[2],reverse=False))\n",
    "\n",
    "cm = plt.get_cmap(colorsMap)\n",
    "cNorm = colx.Normalize(vmin=min(c), vmax=max(c))\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cm)\n",
    "conv_inch_pixel = 5 # sloppy determination must be improved\n",
    "plt.scatter(np.array(x) ,N-np.array(y) ,s=np.array(s)/conv_inch_pixel, c=scalarMap.to_rgba(c)) # beware image origine the upper leeft corner                                                                          #        plot origine lower left corner\n",
    "plt.xlim(0,M)\n",
    "plt.ylim(0,N)\n",
    "scalarMap.set_array(c)\n",
    "\n",
    "_ = plt.yticks(ticks=[N,N-100, N-200, N-300, N-400, N-500],labels=[0,100,200,300,400,500],\n",
    "                               rotation=0)\n",
    "plt.colorbar(scalarMap)\n",
    "plt.title(\"Size and height\")\n",
    "\n",
    "# features size histogram plot\n",
    "plt.subplot(3,2,5)\n",
    "h = plt.hist(df['size'], bins=100)\n",
    "plt.title(f'Size histogram')\n",
    "plt.ylabel('size (pix\\u00B2)')\n",
    "\n",
    "# features size box plot\n",
    "plt.subplot(3,2,6)\n",
    "_ = plt.boxplot(df['size'])\n",
    "plt.title(f'Size bbox')\n",
    "_ = plt.ylabel('size (pix\\u00B2)')\n",
    "\n",
    "if store_flag:\n",
    "    df_th.to_excel(root_output/file_xlsx_th)\n",
    "    df.to_excel(root_output/file_xlsx_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Profiles plots\n",
    "'''\n",
    "# 3rd party imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "for idx,col in enumerate([480,500,550,570]): #[50,80,150,500,550,570]\n",
    "    plt.subplot(3,2,idx+1)\n",
    "    plt.plot(im_synth[col,:],label=\"raw image\" )\n",
    "    plt.plot(im_corr[col,:],'--',label=\"top hat\" )\n",
    "    plt.plot([0,M],[threshold,threshold],'k--',label=\"threshold\" )\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
